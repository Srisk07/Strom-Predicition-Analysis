# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EK9v9yxyLwTRDg71DXI6iFXHdckOCjWJ
"""

!pip install streamlit
!pip install pyngrok
!pip install requests
!pip install pandas
!pip install joblib
!pip install numpy
!pip install datetime
!pip install matplotlib
!pip install seaborn

import streamlit as st
import requests
import pandas as pd
import joblib
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns

# ‚úÖ OpenWeatherMap API Key
API_KEY =

from sklearn.preprocessing import StandardScaler
import joblib
import numpy as np

# Generate a sample dataset (Replace with your actual dataset)
data = np.random.rand(100, 4)  # 100 samples, 4 features

# Train and save the scaler
scaler = StandardScaler()
scaler.fit(data)
joblib.dump(scaler, "scaler.pkl")

print("‚úÖ Scaler saved as scaler.pkl")

import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Generate dummy data
X, y = make_classification(n_samples=1000, n_features=4, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Save the model
joblib.dump(model, "storm_prediction_model.pkl")
print("‚úÖ Model saved as storm_prediction_model.pkl")

# Save the scaler
scaler = StandardScaler()
scaler.fit(X_train)
joblib.dump(scaler, "scaler.pkl")
print("‚úÖ Scaler saved as scaler.pkl")

# ‚úÖ Load trained model & scaler
model = joblib.load("storm_prediction_model.pkl")
scaler = joblib.load("scaler.pkl")

# ‚úÖ Function to fetch historical weather data (last 5 days)
def fetch_historical_weather(city):
    end_time = int(datetime.now().timestamp())
    start_time = end_time - (5 * 24 * 60 * 60)  # 5 days ago
    url = f"http://history.openweathermap.org/data/2.5/history/city?q={city}&type=hour&start={start_time}&end={end_time}&appid={API_KEY}&units=metric"
    response = requests.get(url).json()

    history = []
    if "list" in response:
        for entry in response["list"]:
            history.append({
                "City": city,
                "Date": datetime.utcfromtimestamp(entry["dt"]).strftime('%Y-%m-%d'),
                "Temperature": entry["main"]["temp"],
                "Humidity": entry["main"]["humidity"],
                "Pressure": entry["main"]["pressure"],
                "Wind Speed": entry["wind"]["speed"]
            })
    return history

# ‚úÖ Function to fetch 3-day weather forecast
def fetch_future_weather(city):
    url = f"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={API_KEY}&units=metric"
    response = requests.get(url).json()

    future_data = []
    unique_dates = set()
    if "list" in response:
        for entry in response["list"]:
            date = datetime.utcfromtimestamp(entry["dt"]).strftime('%Y-%m-%d')
            if date not in unique_dates:
                future_data.append({
                    "City": city,
                    "Date": date,
                    "Temperature": entry["main"]["temp"],
                    "Humidity": entry["main"]["humidity"],
                    "Pressure": entry["main"]["pressure"],
                    "Wind Speed": entry["wind"]["speed"]
                })
                unique_dates.add(date)
            if len(unique_dates) == 3:  # Ensure only next 3 unique days
                break
    return future_data

# ‚úÖ Function to run storm prediction
def predict_storm(city, temp, humidity, pressure, wind_speed):
    input_data = pd.DataFrame([[temp, humidity, pressure, wind_speed]], columns=["Temperature", "Humidity", "Pressure", "Wind Speed"])
    input_scaled = scaler.transform(input_data)
    prediction = model.predict(input_scaled)
    return "üå™Ô∏è Storm Expected" if prediction[0] == 1 else "‚úÖ No Storm"

# ‚úÖ Visualization
# Fetch historical or future weather data first and store it in a DataFrame
# ‚úÖ Cities for Weather Fetching
cities = ["New York", "Los Angeles", "Chicago", "Houston", "Phoenix"]  # Replace with the desired city
# Use either historical or future weather data
# df = pd.DataFrame(fetch_historical_weather(city))

all_future_data = []  # Initialize an empty list to store data for all cities

for city in cities:  # Loop through each city
    future_data = fetch_future_weather(city)  # Fetch weather data for the current city
    all_future_data.extend(future_data)  # Append the data to the all_future_data list

df = pd.DataFrame(all_future_data)  # Create a DataFrame from the combined data for all cities

plt.figure(figsize=(10, 5))
sns.lineplot(x=df["Date"], y=df["Wind Speed"], hue=df["City"], marker="o", palette="coolwarm")
plt.xlabel("Date")
plt.ylabel("Wind Speed (m/s)")
plt.title("Wind Speed Forecast for Next 3 Days")
plt.xticks(rotation=30)
plt.grid(True)
plt.show()

plt.figure(figsize=(10,5))
sns.barplot(x=df["Date"], y=df["Temperature"], hue=df["City"], palette="viridis")
plt.xlabel("Date")
plt.ylabel("Temperature (¬∞C)")
plt.title("Temperature Forecast for Next 3 Days")
plt.xticks(rotation=30)
plt.legend(title="City")
plt.grid(True)
plt.show()

!pip install pyngrok

!ngrok authtoken 2u9rvYpUnDoVa5NLcWamJimcWsX_98TFxMZroaaaxnuQ4Fe4  # Replace <YOUR_AUTHTOKEN> with your actual authtoken
from pyngrok import ngrok
public_url = ngrok.connect(port="8501")
print(public_url)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# 
# # Streamlit App Title
# st.title("üå©Ô∏è Storm Prediction System")
# 
# st.write("This is a simple Storm Prediction interface.")
#

!ls -l app.py

!pip install --upgrade streamlit
!pip install pyngrok